{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPVqKz3yH1VVE9HCUfAEof/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anadiedrichs/2023-vision-computacional/blob/main/TP3_vision_Diedrichs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Trabajo Práctico Nro 3\n",
        "\n",
        "\n",
        "Ana Laura Diedrichs\n",
        "\n",
        "SIU a0902\n",
        "\n",
        "9Co2022\n",
        "\n",
        "\n",
        " Encontrar el logotipo de la gaseosa dentro de las imágenes provistas en Material_TPs/TP3/images a partir del template Material_TPs/TP3/template\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HU0yfC1mvxTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Si queremos que las imágenes sean mostradas en una ventana emergente quitar el inline\n",
        "%matplotlib inline\n",
        "# OpenCV-Python utiliza NumPy para el manejo de imágenes\n",
        "import numpy as np\n",
        "# cv2 es el módulo python para acceder a OpenCV\n",
        "import cv2 as cv\n",
        "# matplotlib para mostrar imágenes, perfiles, histogramas, etc\n",
        "import matplotlib.pyplot as plt\n",
        "# para importar imagenes desde urls\n",
        "from skimage import io\n",
        "# mostrar imagenes opencv en googlecolab\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "k3ZYuENmE_4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Muestro la imagen del template"
      ],
      "metadata": {
        "id": "hYzgooLY88vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url_template = \"https://www.dropbox.com/s/rn5d4oubths7xmz/pattern.png?dl=1\"\n",
        "img = io.imread(url_template)\n",
        "img_template = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(img_template, cmap='gray')"
      ],
      "metadata": {
        "id": "JeusoF8g7_MC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.(4 puntos) Obtener una detección del logo en cada imagen sin falsos positivos\n"
      ],
      "metadata": {
        "id": "wAMjrI1fv2l0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def template_matching(imagen, plantilla, t = 0.7):\n",
        "  'Recibe imágenes y se puede elegir el threshold / umbral'\n",
        "  # Convert the images to grayscale\n",
        "  copia = imagen.copy()\n",
        "  input_gray = cv.cvtColor(imagen, cv.COLOR_BGR2GRAY)\n",
        "  template_gray = cv.cvtColor(plantilla, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "  # Find the dimensions of the template image\n",
        "  h,w = template_gray.shape\n",
        "\n",
        "  # Use the cv2.matchTemplate() function to find the correlation between the images\n",
        "  result = cv.matchTemplate(input_gray, template_gray, cv.TM_CCOEFF_NORMED)\n",
        "\n",
        "  # Set the threshold for the correlation coefficient\n",
        "  threshold = t\n",
        "  loc = np.where(result >= threshold)\n",
        "\n",
        "  # Check if there are any good matches\n",
        "  if len(loc[0]) > 0:\n",
        "      # Draw a rectangle around each good match\n",
        "      for pt in zip(*loc[::-1]):\n",
        "          cv.rectangle(copia, pt, (pt[0] + w, pt[1] + h), (0, 0, 255), 2)\n",
        "      print(\"Coincidencia encontrada\")\n",
        "  else:\n",
        "      print(\"Nada por aquí\")\n",
        "\n",
        "  # Find the location of the maximum value in the result image\n",
        "  min_val, max_val, min_loc, max_loc = cv.minMaxLoc(result)\n",
        "\n",
        "  # Draw a rectangle around the maximum value in the result image\n",
        "  top_left = max_loc\n",
        "  bottom_right = (top_left[0] + plantilla.shape[1], top_left[1] + plantilla.shape[0])\n",
        "  img_matches = cv.rectangle(copia, top_left, bottom_right, (0, 0, 255), 2)\n",
        "\n",
        "  return img_matches\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nbTKyzwErrFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def template_matching_intro(imagen,plantilla):\n",
        "\n",
        "    img_gray = cv.cvtColor(imagen, cv.COLOR_BGR2GRAY)\n",
        "    template = cv.cvtColor(plantilla, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Hago una copia de la imagen porque ciclo a ciclo le dibujo rectángulos\n",
        "    img_salida =  cv.cvtColor(imagen, cv.COLOR_BGR2RGB)\n",
        "\n",
        "    h,w = template.shape\n",
        "    # Aplicamos la coincidencia de patrones\n",
        "    #--------------------------------------\n",
        "    res = cv.matchTemplate(img_gray, template, cv.TM_SQDIFF_NORMED)\n",
        "\n",
        "    # Encontramos los valores máximos y mínimos\n",
        "    min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
        "\n",
        "    # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
        "    #if method in [cv.TM_SQDIFF, cv.TM_SQDIFF_NORMED]:\n",
        "    top_left = min_loc\n",
        "    #else:\n",
        "    #    top_left = max_loc\n",
        "\n",
        "    # Marcamos el lugar donde lo haya encontrado\n",
        "    #----------------------------------------\n",
        "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
        "    cv.rectangle(img_salida,top_left, bottom_right, 255, 2)\n",
        "\n",
        "    # Graficamos el procesamiento y la salida\n",
        "    #----------------------------------------\n",
        "    plt.figure()\n",
        "\n",
        "    # Resultado de coincidencia\n",
        "    plt.subplot(121),plt.imshow(res,cmap = 'gray')\n",
        "    plt.title('Matching Result'), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "    # Imagen original con recuadros\n",
        "    plt.subplot(122),plt.imshow(img_salida)\n",
        "    plt.title('Detected Point'), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "    plt.suptitle('TM_CCOEFF_NORMED')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "dc_vG-u9S8Kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imagen COCA-COLA-LOGO.jpg"
      ],
      "metadata": {
        "id": "Jua4JQ1FU13P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# template\n",
        "url_template = \"https://www.dropbox.com/s/rn5d4oubths7xmz/pattern.png?dl=1\"\n",
        "img = io.imread(url_template)\n",
        "# imagen\n",
        "url = \"https://www.dropbox.com/s/lxv9drjd0vzmzg2/COCA-COLA-LOGO.jpg?dl=1\"\n",
        "myImg = io.imread(url)"
      ],
      "metadata": {
        "id": "V5uYkKaSokDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template_matching_intro(myImg, plantilla=img)"
      ],
      "metadata": {
        "id": "58I5comEUCrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "salida = template_matching(myImg, plantilla=img, t = 0.6)\n",
        "\n",
        "# Display the results\n",
        "plt.figure(figsize = (20,10))\n",
        "plt.imshow(salida)"
      ],
      "metadata": {
        "id": "KuxPGXXvUWIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imagen coca_logo_1.png"
      ],
      "metadata": {
        "id": "6QWAaHseU9cj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imagen\n",
        "url = \"https://www.dropbox.com/s/bifxxgy5l0vicf0/coca_logo_1.png?dl=1\"\n",
        "myImg = io.imread(url)\n",
        "#template_matching_intro(myImg, plantilla=img)"
      ],
      "metadata": {
        "id": "yKvGW6c-VN8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La ejecución anterior da error porque la resolución de la imagen coca_logo_1.png es menor a la del template, corrijo achicando la imagen del template con pyrDown"
      ],
      "metadata": {
        "id": "UNeTKxh7VYUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Esto aumenta la resolución inyectando filas y columnas de ceros intercaladas y luego\n",
        "# convolucionando el resultado con el núcleo gaussiano 5 × 5 multiplicado por 4\n",
        "img_nivel_2 = cv.pyrDown(img)\n",
        "\n",
        "# Muestro el resultado por subir el nivel\n",
        "#cv2_imshow(img_nivel_2)\n",
        "template_matching_intro(myImg, plantilla=img_nivel_2)"
      ],
      "metadata": {
        "id": "nwCCD_EkUQrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "salida = template_matching(myImg, plantilla=img_nivel_2, t = 0.9)\n",
        "\n",
        "# Display the results\n",
        "plt.figure(figsize = (20,10))\n",
        "plt.imshow(salida)"
      ],
      "metadata": {
        "id": "hATou5HeV6M4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modificación al preprocesamiento de las imágenes previo a aplicar template matching\n",
        "\n"
      ],
      "metadata": {
        "id": "mELCbIu4_MCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the image image, convert it to grayscale, and detect edges\n",
        "# template\n",
        "url_template = \"https://www.dropbox.com/s/rn5d4oubths7xmz/pattern.png?dl=1\"\n",
        "img = io.imread(url_template)\n",
        "template = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "template = cv.Canny(template, 50, 200)\n",
        "(tH, tW) = template.shape[:2]\n",
        "cv2_imshow( template)"
      ],
      "metadata": {
        "id": "y7PQonRn_R9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urls = [\"https://www.dropbox.com/s/lxv9drjd0vzmzg2/COCA-COLA-LOGO.jpg?dl=1\",\n",
        "     \"https://www.dropbox.com/s/bifxxgy5l0vicf0/coca_logo_1.png?dl=1\",\n",
        "      \"https://www.dropbox.com/s/a4y0lsjykqzmm7b/coca_logo_2.png?dl=1\",\n",
        "      \"https://www.dropbox.com/s/o1rtc9zsu81u0eq/coca_retro_1.png?dl=1\",\n",
        "      \"https://www.dropbox.com/s/jgxf1g1v94wdw6r/coca_retro_2.png?dl=1\",\n",
        "      \"https://www.dropbox.com/s/pfwbo9nnyi5ifyq/logo_1.png?dl=1\",\n",
        "      \"https://www.dropbox.com/s/z0sfx2k08ou61at/coca_multi.png?dl=1\"]\n"
      ],
      "metadata": {
        "id": "6xOM6XOoQOro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import imutils\n",
        "visualize = False\n",
        "\n",
        "# loop over the images to find the template in\n",
        "for imagePath in urls:\n",
        "  # load the image, convert it to grayscale, and initialize the\n",
        "  # bookkeeping variable to keep track of the matched region\n",
        "  image = io.imread(imagePath)\n",
        "  gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
        "  found = False\n",
        "  # loop over the scales of the image\n",
        "  for scale in np.linspace(0.2, 1.0, 10)[::-1]: # el 10 antes era 20\n",
        "    # resize the image according to the scale, and keep track\n",
        "    # of the ratio of the resizing\n",
        "    resized = imutils.resize(gray, width = int(gray.shape[1] * scale))\n",
        "    r = gray.shape[1] / float(resized.shape[1])\n",
        "\n",
        "    # if the resized image is smaller than the template, then break\n",
        "    # from the loop, para evitar error en opencv\n",
        "    if resized.shape[0] < tH or resized.shape[1] < tW:\n",
        "      break\n",
        "    found = True\n",
        "    # detect edges in the resized, grayscale image and apply template\n",
        "    # matching to find the template in the image\n",
        "    edged = cv.Canny(resized, 50, 200)\n",
        "    result = cv.matchTemplate(edged, template, cv.TM_CCOEFF)\n",
        "    _, maxVal, _, maxLoc = cv.minMaxLoc(result)\n",
        "\n",
        "    # check to see if the iteration should be visualized\n",
        "    if( visualize == True):\n",
        "      # draw a bounding box around the detected region\n",
        "      clone = np.dstack([edged, edged, edged])\n",
        "      cv.rectangle(clone, (maxLoc[0], maxLoc[1]),\n",
        "        (maxLoc[0] + tW, maxLoc[1] + tH), (0, 0, 255), 2)\n",
        "      cv2_imshow( clone)\n",
        "\n",
        "    (startX, startY) = (int(maxLoc[0] * r), int(maxLoc[1] * r))\n",
        "    (endX, endY) = (int((maxLoc[0] + tW) * r), int((maxLoc[1] + tH) * r))\n",
        "    # draw a bounding box around the detected result and display the image\n",
        "    icopia = image.copy()\n",
        "    cv.rectangle(icopia, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
        "    cv2_imshow(icopia)\n"
      ],
      "metadata": {
        "id": "MklnK-kcAKbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.(4 puntos) Plantear y validar un algoritmo para múltiples detecciones en la imagen\n",
        "coca_multi.png con el mismo template del ítem 1\n"
      ],
      "metadata": {
        "id": "RlPZySGYv6XL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coca_multi_path = \"https://www.dropbox.com/s/z0sfx2k08ou61at/coca_multi.png?dl=1\""
      ],
      "metadata": {
        "id": "uNlQpNafwCXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the image image, convert it to grayscale, and detect edges\n",
        "# template\n",
        "url_template = \"https://www.dropbox.com/s/rn5d4oubths7xmz/pattern.png?dl=1\"\n",
        "img = io.imread(url_template)\n",
        "template = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "template = cv.Canny(template, 50, 200)\n",
        "(tH, tW) = template.shape[:2]\n",
        "cv2_imshow( template)"
      ],
      "metadata": {
        "id": "NZwFOSuijJFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template.shape[:2]"
      ],
      "metadata": {
        "id": "aTj56He7jeXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import imutils\n",
        "from imutils.object_detection import non_max_suppression\n",
        "\n",
        "visualize = True\n",
        "thresh = 0.1"
      ],
      "metadata": {
        "id": "aAxpCukWjJ_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the image, convert it to grayscale, and initialize the\n",
        "# bookkeeping variable to keep track of the matched region\n",
        "image = io.imread(coca_multi_path)\n",
        "gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
        "color = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "found = False\n",
        "# loop over the scales of the template\n",
        "for scale in np.linspace(0.2, 1.0, 10)[::-1]: # el 10 antes era 20\n",
        "  # resize the image according to the scale, and keep track\n",
        "  # of the ratio of the resizing\n",
        "\n",
        "\n",
        "  template_resized = imutils.resize(template, width = int(template.shape[1] * scale))\n",
        "  (tH, tW) = template_resized.shape[:2]\n",
        "\n",
        "  #resized = imutils.resize(gray, width = int(gray.shape[1] * scale))\n",
        "  r = template_resized.shape[1] / float(template_resized.shape[1])\n",
        "\n",
        "  # if the resized image is smaller than the template, then break\n",
        "  # from the loop, para evitar error en opencv\n",
        "  if gray.shape[0] < tH or gray.shape[1] < tW:\n",
        "    if( visualize == True):\n",
        "      print(\"NOT FOUND Res. \"+ str(scale) + \" Image \"+imagePath)\n",
        "    break\n",
        "\n",
        "  # detect edges in the resized, grayscale image and apply template\n",
        "  # matching to find the template in the image\n",
        "  edged = cv.Canny(gray, 50, 200)\n",
        "  result = cv.matchTemplate(edged, template_resized, cv.TM_SQDIFF)\n",
        "\n",
        "  _, maxVal, _, maxLoc = cv.minMaxLoc(result)\n",
        "  #print(maxVal, maxVal)\n",
        "   # check to see if the iteration should be visualized\n",
        "  if( visualize == True):\n",
        "    # draw a bounding box around the detected region\n",
        "    clone = np.dstack([edged, edged, edged])\n",
        "    cv.rectangle(clone, (maxLoc[0], maxLoc[1]),\n",
        "      (maxLoc[0] + tW, maxLoc[1] + tH), (0, 0, 255), 2)\n",
        "    cv2_imshow( clone)\n",
        "\n",
        "\n",
        "  # Define a threshold\n",
        "  # thresh between 40000000 and 60000000 works\n",
        "  thresh = 50000000\n",
        "\n",
        "  # Select rectangles with confidence less than threshold for TM_SQDIFF\n",
        "  (y_points, x_points) = np.where(result <= thresh)\n",
        "\n",
        "  # Select rectangles with\n",
        "  # confidence greater than threshold\n",
        "  (y_points, x_points) = np.where(result >= thresh)\n",
        "\n",
        "  # initialize our list of rectangles\n",
        "  boxes = list()\n",
        "\n",
        "  # loop over the starting (x, y)-coordinates again\n",
        "  for (x, y) in zip(x_points, y_points):\n",
        "      # update our list of rectangles\n",
        "      boxes.append((x, y, x + tW, y + tH))\n",
        "  print(\"hay \"+str(len(boxes))+ \" cajitas\")\n",
        "  # apply non-maxima suppression to the rectangles\n",
        "  # this will create a single bounding box para evitar que se repitan o superpongan rectangulos\n",
        "  boxes = non_max_suppression(np.array(boxes))\n",
        "  copia = color.copy()\n",
        "  # loop over the final bounding boxes\n",
        "  for (x1, y1, x2, y2) in boxes:\n",
        "      # draw the bounding box on the image\n",
        "      cv.rectangle(copia, (x1, y1), (x2, y2),(255, 0, 0), 3)\n",
        "\n",
        "  cv2_imshow(copia)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QpMP2dPuN1nC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.(2 puntos) Generalizar el algoritmo del item 2 para todas las imágenes.\n",
        "Visualizar los resultados con bounding boxes en cada imagen mostrando el nivel de confianza\n",
        "de la detección.\n"
      ],
      "metadata": {
        "id": "MdNiVpbZv7wr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qF_oLgdvwzS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ve_7WdhvF1z6"
      },
      "outputs": [],
      "source": [
        "template_image = img_template\n",
        "\n",
        "height, width = template_image.shape\n",
        "\n",
        "for url in urls: # por cada imagen\n",
        "  myImg = io.imread(url)\n",
        "  img_rgb= cv.cvtColor(myImg, cv.COLOR_BGR2RGB)\n",
        "  target_image= cv.cvtColor(myImg, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "  # Realizar el template matching\n",
        "  result = cv.matchTemplate(target_image, template_image, cv.TM_CCOEFF_NORMED)\n",
        "\n",
        "  # Establecer un umbral para la detección\n",
        "  threshold = 0.70\n",
        "  loc = np.where(result >= threshold)\n",
        "\n",
        "  img_salida = img_rgb.copy()\n",
        "\n",
        "  for pt in zip(*loc[::-1]):\n",
        "    cv.rectangle(img_salida, pt, (pt[0] + w, pt[1] + h), (0,0,255), 2)\n",
        "\n",
        "  # Graficamos el procesamiento y la salida\n",
        "  #----------------------------------------\n",
        "  plt.figure()\n",
        "\n",
        "  # Resultado de coincidencia\n",
        "  plt.subplot(121),plt.imshow(res,cmap = 'gray')\n",
        "  plt.title('Matching Result'), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "  # Imagen original con recuadros\n",
        "  plt.subplot(122),plt.imshow(img_salida)\n",
        "  plt.title('Detected Point'), plt.xticks([]), plt.yticks([])\n",
        "  plt.show()\n",
        "\n",
        "\n"
      ]
    }
  ]
}